import json
import random
import os
from openai import OpenAI
from docx import Document
from dotenv import load_dotenv

# Carrega vari√°veis do .env
load_dotenv()

# Configura√ß√£o do cliente OpenAI
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)
model_name = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# Verifica√ß√£o das vari√°veis obrigat√≥rias
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("A vari√°vel OPENAI_API_KEY n√£o est√° definida no .env")

print(f"Usando modelo: {model_name}")

def read_docx_content(file_path):
    """
    L√™ o conte√∫do de um arquivo DOCX e retorna o texto completo.
    """
    try:
        doc = Document(file_path)
        content = []
        
        # Extrai todos os par√°grafos
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                content.append(paragraph.text.strip())
        
        # Junta todo o conte√∫do
        full_content = '\n'.join(content)
        return full_content
    except Exception as e:
        print(f"Erro ao ler arquivo {file_path}: {str(e)}")
        return None

def generate_qa_with_gpt(document_content, file_name):
    """
    Gera uma pergunta e resposta baseada no conte√∫do do documento usando OpenAI.
    """
    prompt = f"""
Baseado no seguinte documento administrativo, crie uma pergunta espec√≠fica que REQUEIRA as informa√ß√µes contidas no documento para ser respondida corretamente.

DOCUMENTO:
{document_content}

INSTRU√á√ïES:
1. A pergunta deve ser espec√≠fica e contextual - deve exigir informa√ß√µes √öNICAS deste documento
2. A pergunta deve ser natural e realista - como se algu√©m estivesse procurando informa√ß√µes espec√≠ficas
3. A resposta deve ser precisa e baseada EXCLUSIVAMENTE no conte√∫do fornecido
4. Evite perguntas gen√©ricas que poderiam ser respondidas sem ler o documento

FORMATO DE RESPOSTA (JSON):
{{
    "pergunta": "sua pergunta espec√≠fica aqui",
    "resposta": "sua resposta detalhada baseada no documento"
}}

Responda APENAS com o JSON v√°lido, sem texto adicional.
"""

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=2000,
            service_tier="flex"
        )
        
        # Tenta fazer parse do JSON da resposta
        response_text = response.choices[0].message.content.strip()
        
        # Remove poss√≠veis caracteres extras antes e depois do JSON
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        
        qa_data = json.loads(response_text)
        return qa_data
        
    except json.JSONDecodeError as e:
        print(f"Erro ao fazer parse JSON para {file_name}: {str(e)}")
        print(f"Resposta recebida: {response_text}")
        return None
    except Exception as e:
        print(f"Erro ao gerar Q&A para {file_name}: {str(e)}")
        return None

def select_random_files(directory, n=20):
    """
    Seleciona n arquivos aleat√≥rios da pasta de documentos.
    """
    try:
        all_files = [f for f in os.listdir(directory) if f.endswith('.docx')]
        if len(all_files) < n:
            print(f"Aviso: Apenas {len(all_files)} arquivos encontrados, usando todos.")
            return all_files
        
        selected_files = random.sample(all_files, n)
        return selected_files
    except Exception as e:
        print(f"Erro ao selecionar arquivos: {str(e)}")
        return []

def create_qa_dataset(documents_dir="documentos_gerados", output_file="datasets/qa_dataset.json", n_files=20):
    """
    Cria um dataset de Q&A a partir dos documentos DOCX.
    """
    print(f"Iniciando cria√ß√£o do dataset Q&A...")
    print(f"Diret√≥rio: {documents_dir}")
    print(f"N√∫mero de arquivos: {n_files}")
    
    # Seleciona arquivos aleat√≥rios
    selected_files = select_random_files(documents_dir, n_files)
    
    if not selected_files:
        print("Nenhum arquivo selecionado. Encerrando.")
        return
    
    print(f"Arquivos selecionados: {len(selected_files)}")
    for i, file in enumerate(selected_files, 1):
        print(f"  {i}. {file}")
    
    qa_dataset = []
    
    for i, filename in enumerate(selected_files, 1):
        file_path = os.path.join(documents_dir, filename)
        print(f"\n[{i}/{len(selected_files)}] Processando: {filename}")
        
        # L√™ o conte√∫do do documento
        content = read_docx_content(file_path)
        if not content:
            print(f"  ‚ùå Falha ao ler conte√∫do")
            continue
        
        print(f"  üìÑ Conte√∫do extra√≠do: {len(content)} caracteres")
        
        # Gera pergunta e resposta
        qa_data = generate_qa_with_gpt(content, filename)
        if not qa_data:
            print(f"  ‚ùå Falha ao gerar Q&A")
            continue
        
        # Adiciona ao dataset
        dataset_entry = {
            "arquivo": filename,
            "contexto": content,
            "pergunta": qa_data.get("pergunta", ""),
            "resposta": qa_data.get("resposta", "")
        }
        
        qa_dataset.append(dataset_entry)
        print(f"  ‚úÖ Q&A gerado com sucesso")
        print(f"     Pergunta: {qa_data.get('pergunta', '')[:100]}...")
    
    # Salva o dataset
    if qa_dataset:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(qa_dataset, f, ensure_ascii=False, indent=2)
        
        print(f"\nüéâ Dataset criado com sucesso!")
        print(f"üìä Total de entradas: {len(qa_dataset)}")
        print(f"üíæ Arquivo salvo: {output_file}")
        
        # Mostra uma amostra
        if qa_dataset:
            print(f"\nüìã Exemplo do primeiro item:")
            first_item = qa_dataset[0]
            print(f"   Arquivo: {first_item['arquivo']}")
            print(f"   Pergunta: {first_item['pergunta']}")
            print(f"   Resposta: {first_item['resposta'][:200]}...")
    else:
        print("\n‚ùå Nenhum item foi adicionado ao dataset.")

if __name__ == "__main__":
    # Cria o dataset com 20 arquivos aleat√≥rios
    create_qa_dataset(
        documents_dir="documentos_gerados",
        output_file="datasets/qa_dataset300.json",
        n_files=300
    )
